{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# import statistics\n",
    "# import json\n",
    "# import tiktoken\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import swifter\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "##\n",
    "load_dotenv('../.env') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model \n",
    "\n",
    "Roberta Named Entity works best for this task. \n",
    "\n",
    "Using this version from HF : `mn-xlm-roberta-base-named-entity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnayak/.pyenv/versions/3.11.1/envs/OpenAI@3111/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters -> 277.456901 Mn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "## Roberta based NER\n",
    "roberta = pipeline(\"token-classification\", model=\"2rtl3/mn-xlm-roberta-base-named-entity\", aggregation_strategy=\"simple\")\n",
    "\n",
    "print(\"Number of parameters ->\", roberta.model.num_parameters()/1000000, \"Mn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOC', 'MISC', 'O', 'ORG', 'PER']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "entity_classes = list(roberta.model.config.label2id.keys())\n",
    "entity_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Named entites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the model for multiple text\n",
    "\n",
    "first lets run a test on example text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"\"\"The Rishi Vyasa published this mass of knowledge in both a detailed and\n",
    "an abridged form. It is the wish of the learned in the world to possess\n",
    "the details and the abridgement. Some read the Bharata beginning with the\n",
    "initial mantra (invocation), others with the story of Astika, others with\n",
    "Uparichara, while some Brahmanas study the whole. Men of learning display\n",
    "their various knowledge of the institutes in commenting on the\n",
    "composition. Some are skilful in explaining it, while others, in\n",
    "remembering its contents.\n",
    "\n",
    "The son of Satyavati having, by penance and meditation, analysed the\n",
    "eternal Veda, afterwards composed this holy history, when that learned\n",
    "Brahmarshi of strict vows, the noble Dwaipayana Vyasa, offspring of\n",
    "Parasara, had finished this greatest of narrations, he began to consider\n",
    "how he might teach it to his disciples. And the possessor of the six\n",
    "attributes, Brahma, the world's preceptor, knowing of the anxiety of the\n",
    "Rishi Dwaipayana, came in person to the place where the latter was, for\n",
    "gratifying the saint, and benefiting the people. And when Vyasa,\n",
    "surrounded by all the tribes of Munis, saw him, he was surprised; and,\n",
    "standing with joined palms, he bowed and ordered a seat to be brought.\n",
    "And Vyasa having gone round him who is called Hiranyagarbha seated on\n",
    "that distinguished seat stood near it; and being commanded by Brahma\n",
    "Parameshthi, he sat down near the seat, full of affection and smiling in\n",
    "joy. Then the greatly glorious Vyasa, addressing Brahma Parameshthi,\n",
    "said, \"O divine Brahma, by me a poem hath been composed which is greatly\n",
    "respected. The mystery of the Veda, and what other subjects have been\n",
    "explained by me; the various rituals of the Upanishads with the Angas;\n",
    "the compilation of the Puranas and history formed by me and named after\n",
    "the three divisions of time, past, present, and future; the determination\n",
    "of the nature of decay, fear, disease, existence, and non-existence, a\n",
    "description of creeds and of the various modes of life; rule for the four\n",
    "castes, and the import of all the Puranas; an account of asceticism and\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the combine_tokens_list function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'The Rishi Vyasa', 'entity': 'MISC'},\n",
       " {'name': 'the Bharata', 'entity': 'MISC'},\n",
       " {'name': 'Astika', 'entity': 'PER'},\n",
       " {'name': 'Uparichara', 'entity': 'PER'},\n",
       " {'name': 'Brahmanas', 'entity': 'MISC'},\n",
       " {'name': 'Satyavati', 'entity': 'PER'},\n",
       " {'name': 'Veda', 'entity': 'MISC'},\n",
       " {'name': 'Brahmarshi', 'entity': 'PER'},\n",
       " {'name': 'Dwaipayana Vyasa', 'entity': 'PER'},\n",
       " {'name': 'Parasara', 'entity': 'PER'},\n",
       " {'name': 'Brahma', 'entity': 'PER'},\n",
       " {'name': 'the Rishi Dwaipayana', 'entity': 'MISC'},\n",
       " {'name': 'Vyasa', 'entity': 'PER'},\n",
       " {'name': 'Munis', 'entity': 'LOC'},\n",
       " {'name': 'Vyasa', 'entity': 'PER'},\n",
       " {'name': 'Hiranyagarbha', 'entity': 'PER'},\n",
       " {'name': 'Brahma Parameshthi', 'entity': 'PER'},\n",
       " {'name': 'Vyasa', 'entity': 'PER'},\n",
       " {'name': 'Brahma Parameshthi', 'entity': 'PER'},\n",
       " {'name': 'Brahma', 'entity': 'PER'},\n",
       " {'name': 'the Veda', 'entity': 'MISC'},\n",
       " {'name': 'the Upanishads', 'entity': 'MISC'},\n",
       " {'name': 'the Angas', 'entity': 'MISC'},\n",
       " {'name': 'the Puranas', 'entity': 'MISC'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results = roberta(text)\n",
    "# entities = combine_tokens_list(ner_results, stop_words, metadata = {'some': 'other'})\n",
    "entities = []\n",
    "for result in ner_results:\n",
    "    entities = entities + [{'name': result['word'], 'entity': result['entity_group']}]\n",
    "\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a reverse indexed entities dataframe here \n",
    "\n",
    "The idea is to create a dataframe of entities and tag every section they appear in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reverse index\n",
    "## Index all the text chunks that contain a particular named entity. \n",
    "\n",
    "def row2NamedEntities(row):\n",
    "    # print(row)\n",
    "    ner_results = roberta(row['text'])\n",
    "    metadata = {'chunk_id': row['chunk_id']}\n",
    "    entities = []\n",
    "    for result in ner_results:\n",
    "        entities = entities + [{'name': result['word'], 'entity': result['entity_group'], **metadata}]\n",
    "        \n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfText2DfNE(dataframe):\n",
    "    ## Takes a dataframe from the parsed data and returns dataframe with named entities. \n",
    "    ## The input dataframe must have a text and a chunk_id column. \n",
    "\n",
    "    ## Using swifter for parallelism\n",
    "    ## 1. Calculate named entities for each row of the dataframe. \n",
    "    results = dataframe.apply(row2NamedEntities, axis=1)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities. \n",
    "    entities_list = np.concatenate(results).ravel().tolist()\n",
    "\n",
    "    ## Remove all NaN entities\n",
    "    entities_dataframe = pd.DataFrame(entities_list).replace(' ', np.nan)\n",
    "    entities_dataframe = entities_dataframe.dropna(subset=['entity'])\n",
    "\n",
    "    ## Count the number of occurances per chunk id\n",
    "    entities_dataframe = entities_dataframe.groupby(['name', 'entity', 'chunk_id']).size().reset_index(name='count')\n",
    "\n",
    "    return entities_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>entity</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_7a30e824ef804f2d956b7c340355ec0d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_869bb0c9f5f04141a9786af859398348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_956f25c0c15c429dbf75549523a50dca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_9af9d8d833204d4da009adecad490677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_b5f3052a52594a68b4388cfd926eb182</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>vati</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_bfcd527551fc46929ad1153aa8d67b8a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>vigaha</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_be680f27c5e84a3e955c6353299b7e2e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>yagandha</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_5c4b2c4baa9945bab2a81a49f1d0a678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>yana</td>\n",
       "      <td>LOC</td>\n",
       "      <td>cid_b825b13ed08b406da76c9fea6b7d3002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>yodhana</td>\n",
       "      <td>PER</td>\n",
       "      <td>cid_3da40a52398e4685b1e7fbaf40581fac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1328 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name entity                              chunk_id  count\n",
       "0     Abhimanyu    PER  cid_7a30e824ef804f2d956b7c340355ec0d      1\n",
       "1     Abhimanyu    PER  cid_869bb0c9f5f04141a9786af859398348      1\n",
       "2     Abhimanyu    PER  cid_956f25c0c15c429dbf75549523a50dca      1\n",
       "3     Abhimanyu    PER  cid_9af9d8d833204d4da009adecad490677      1\n",
       "4     Abhimanyu    PER  cid_b5f3052a52594a68b4388cfd926eb182      4\n",
       "...         ...    ...                                   ...    ...\n",
       "1323       vati    PER  cid_bfcd527551fc46929ad1153aa8d67b8a      1\n",
       "1324     vigaha    PER  cid_be680f27c5e84a3e955c6353299b7e2e      1\n",
       "1325   yagandha    PER  cid_5c4b2c4baa9945bab2a81a49f1d0a678      1\n",
       "1326       yana    LOC  cid_b825b13ed08b406da76c9fea6b7d3002      1\n",
       "1327    yodhana    PER  cid_3da40a52398e4685b1e7fbaf40581fac      1\n",
       "\n",
       "[1328 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_directory = directory/\"named_entities\"\n",
    "file_list = glob.glob(f\"{directory}/*.csv\")\n",
    "df_text = pd.read_csv(directory/\"tiny_tales_summaries.csv\", sep=\"|\")\n",
    "dfne = dfText2DfNE(df_text)\n",
    "dfne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Index each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename : summaries_combined.csv ...\n",
      "Skipping:  summaries_combined.csv\n",
      "Filename : tiny_tales_summaries.csv ...\n",
      "Wrote file : tiny_tales_summaries_named_entities.csv\n",
      "Filename : km_ganguli_translation_6.csv ...\n",
      "Wrote file : km_ganguli_translation_6_named_entities.csv\n",
      "Filename : km_ganguli_translation_14.csv ...\n",
      "Wrote file : km_ganguli_translation_14_named_entities.csv\n",
      "Filename : km_ganguli_translation_15.csv ...\n",
      "Wrote file : km_ganguli_translation_15_named_entities.csv\n",
      "Filename : km_ganguli_translation_7.csv ...\n",
      "Wrote file : km_ganguli_translation_7_named_entities.csv\n",
      "Filename : km_ganguli_translation_5.csv ...\n",
      "Wrote file : km_ganguli_translation_5_named_entities.csv\n",
      "Filename : km_ganguli_translation_17.csv ...\n",
      "Wrote file : km_ganguli_translation_17_named_entities.csv\n",
      "Filename : km_ganguli_translation_16.csv ...\n",
      "Wrote file : km_ganguli_translation_16_named_entities.csv\n",
      "Filename : km_ganguli_translation_4.csv ...\n",
      "Wrote file : km_ganguli_translation_4_named_entities.csv\n",
      "Filename : km_ganguli_translation_12.csv ...\n",
      "Wrote file : km_ganguli_translation_12_named_entities.csv\n",
      "Filename : km_ganguli_translation_13.csv ...\n",
      "Wrote file : km_ganguli_translation_13_named_entities.csv\n",
      "Filename : km_ganguli_translation_1.csv ...\n",
      "Wrote file : km_ganguli_translation_1_named_entities.csv\n",
      "Filename : km_ganguli_translation_3.csv ...\n",
      "Wrote file : km_ganguli_translation_3_named_entities.csv\n",
      "Filename : tiny_tales_glossary.csv ...\n",
      "Skipping:  tiny_tales_glossary.csv\n",
      "Filename : km_ganguli_translation_11.csv ...\n",
      "Wrote file : km_ganguli_translation_11_named_entities.csv\n",
      "Filename : km_ganguli_translation_10.csv ...\n",
      "Wrote file : km_ganguli_translation_10_named_entities.csv\n",
      "Filename : km_ganguli_translation_2.csv ...\n",
      "Wrote file : km_ganguli_translation_2_named_entities.csv\n",
      "Filename : km_ganguli_translation_9.csv ...\n",
      "Wrote file : km_ganguli_translation_9_named_entities.csv\n",
      "Filename : kaggle_tilak_summaries.csv ...\n",
      "Wrote file : kaggle_tilak_summaries_named_entities.csv\n",
      "Filename : km_ganguli_translation_8.csv ...\n",
      "Wrote file : km_ganguli_translation_8_named_entities.csv\n",
      "Filename : km_ganguli_translation_18.csv ...\n",
      "Wrote file : km_ganguli_translation_18_named_entities.csv\n",
      "Filename : wikipedia_parva_summaries.csv ...\n",
      "Wrote file : wikipedia_parva_summaries_named_entities.csv\n"
     ]
    }
   ],
   "source": [
    "ner_directory = directory/\"named_entities\"\n",
    "file_list = glob.glob(f\"{directory}/*.csv\")\n",
    "\n",
    "for file in file_list:\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    print(\"Filename :\", file_name, '...')\n",
    "    if file_name in ['tiny_tales_glossary.csv', 'summaries_combined.csv']:\n",
    "    # if not file_name in ['wikipedia_parva_summaries.csv']:\n",
    "        print('Skipping: ', file_name)\n",
    "        continue\n",
    "\n",
    "    df_text = pd.read_csv(directory/file_name, sep=\"|\")\n",
    "    df_ne = dfText2DfNE(df_text)\n",
    "    df_ne['file'] = file_name\n",
    "    outfile_name = f\"{file_name.replace('.csv', '_named_entities.csv')}\"\n",
    "    df_ne.to_csv(ner_directory/outfile_name, index=False, sep=\"|\")\n",
    "    print(\"Wrote file :\", outfile_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
